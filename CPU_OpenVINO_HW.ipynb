{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febba31b-151d-45dc-bffd-c8c881fe287b",
   "metadata": {},
   "source": [
    "# OpenVINO \n",
    "\n",
    "## –£—Å—Ç–∞–Ω–æ–≤–∏–º –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d41e2-e0ec-4d0a-8500-ce5542cada38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -U openvino nncf\n",
    "# # –∏–ª–∏ –ø—Ä–µ-—Ä–µ–ª–∏–∑–Ω–∞—è –≤–µ—Ä—Å–∏—è:\n",
    "#!pip install --pre -U openvino --extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly git+https://github.com/openvinotoolkit/nncf.git\n",
    "\n",
    "#!pip install transformers[torch] datasets evaluate ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e47b0-17c4-433a-9862-dbcc341fbe36",
   "metadata": {},
   "source": [
    "## –°–∫–∞—á–∏–≤–∞–µ–º –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –ú–æ–¥–µ–ª—å\n",
    "\n",
    "–ë–µ—Ä–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ [Huggingface Hub](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending&search=sst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe5515-d107-4218-809e-f2dbde0c29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_id = \"philschmid/MiniLM-L6-H384-uncased-sst2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "hf_model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "hf_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ca21d",
   "metadata": {},
   "source": [
    "–°–æ—Ö—Ä–∞–Ω–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d840b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(hf_model.state_dict(), \"model_sst.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafc42d-44e3-4551-928b-b35f72f5739a",
   "metadata": {},
   "source": [
    "## –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ú–æ–¥–µ–ª—å –≤ OpenVINO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n",
      "torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "hf_model.eval()\n",
    "inputs = {**tokenizer(\"This lesson was amazing!\", \n",
    "                      return_tensors=\"pt\")}\n",
    "ov_model = ov.convert_model(hf_model, example_input=v)\n",
    "ov.save_model(ov_model, 'model.xml')\n",
    "\n",
    "compiled_model = ov.compile_model(ov_model)\n",
    "print(compiled_model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180f9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023, 10800,  2001,  6429,   999,   102]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430162",
   "metadata": {},
   "source": [
    "–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å –ø—Ä–æ—Å—Ç—ã–º –≤—Ö–æ–¥–Ω—ã–º —Ç–µ–Ω–∑–æ—Ä–æ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad7b85-8ec6-4ba6-9cd7-18c859df16aa",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:\n",
    "\n",
    "- PyTorch accuracy:  **0.90138**\n",
    "- OpenVINO accuracy: **0.90138**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdbcbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3fb45710-d3f2-41bc-8d67-269b8b12abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch accuracy:  0.9013761467889908\n",
      "OpenVINO accuracy: 0.9013761467889908\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "\n",
    "val_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def accuracy_evaluate(model, dataset=val_dataset, accuracy=accuracy):   \n",
    "    for sample in dataset:\n",
    "        tokenized = {**tokenizer(sample[\"sentence\"], return_tensors=\"pt\")}\n",
    "        logits = model(tokenized)[\"logits\"]\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        accuracy.add(references=sample[\"label\"], predictions=pred)\n",
    "\n",
    "    return accuracy.compute()[\"accuracy\"]\n",
    "\n",
    "\n",
    "print(f\"PyTorch accuracy:  {accuracy_evaluate(lambda x: hf_model(**x))}\")\n",
    "print(f\"OpenVINO accuracy: {accuracy_evaluate(compiled_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215c7a2-4011-4f61-94e8-cb48cc8c4312",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "–î–æ–±–∞–≤–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–æ–≤ –≤ –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e13ead",
   "metadata": {},
   "source": [
    "* Pytorch:   7.33648s, FPS=118.858, latency: 0.00647s, 0.00830s, 0.01716s\n",
    "* Openvino:  5.27496s, FPS=165.309, latency: 0.00343s, 0.00606s, 0.01561s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d80b6-9988-4dc1-927a-a2d1a5bfa382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch:   20.02967s, FPS=43.535, latency: 0.00604s, 0.00750s, 0.01791s\n",
      "Openvino:  15.10048s, FPS=57.747, latency: 0.00312s, 0.00576s, 0.01241s\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "from statistics import median\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def benchmark(model, dataset):\n",
    "    tokenized_dataset = [{**tokenizer(sample[\"sentence\"], return_tensors=\"pt\")} for sample in dataset]\n",
    "\n",
    "    # warmup\n",
    "    for data in tokenized_dataset[:10]:\n",
    "        model(data)\n",
    "        \n",
    "    times = []\n",
    "    for _ in range(3):\n",
    "        for data in tokenized_dataset:\n",
    "            start = perf_counter()\n",
    "            model(data)\n",
    "            end = perf_counter()\n",
    "            times.append(end - start)\n",
    "\n",
    "    return (\n",
    "        f\"{sum(times):.5f}s, FPS={(len(dataset) / sum(times)):.3f}, \"\n",
    "        f\"latency: {min(times):.5f}s, {median(times):.5f}s, {max(times):.5f}s\"\n",
    "    )\n",
    "\n",
    "print(\"Pytorch:  \", benchmark(lambda x: hf_model(**x), val_dataset))\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_model(x), val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9cec1-309b-457d-b388-d4bdf0792762",
   "metadata": {},
   "source": [
    "## Inference Hints\n",
    "\n",
    "–°–∫–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å —Ä–∞–∑–Ω—ã–º–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —Ö–∏–Ω—Ç–∞–º–∏ –∏ —Å—Ä–∞–≤–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8303d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPU', 'GPU']\n",
      "['FP32', 'INT8', 'BIN', 'EXPORT_IMPORT']\n"
     ]
    }
   ],
   "source": [
    "import openvino.properties as props\n",
    "import openvino.properties.hint as hints\n",
    "\n",
    "core = ov.Core()\n",
    "print(core.available_devices)\n",
    "print(core.get_property('CPU', props.device.capabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_througput = ov.compile_model(\n",
    "    ov_model, \n",
    "    \"CPU\", \n",
    "    {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    ")\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_througput(x), val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a653f8e-6b4a-4727-ad67-7414973aee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  10.86417s, FPS=80.264, latency: 0.00192s, 0.00393s, 0.01735s\n"
     ]
    }
   ],
   "source": [
    "ov_model = ov.convert_model(hf_model, example_input= dict(inputs))\n",
    "\n",
    "compiled_througput = ov.compile_model(\n",
    "    ov_model, \n",
    "    \"CPU\", \n",
    "    {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    ")\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_througput(x), val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee26a4-edb8-47cc-a533-659cba5e4418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  11.55482s, FPS=75.466, latency: 0.00233s, 0.00439s, 0.00849s\n"
     ]
    }
   ],
   "source": [
    "compiled_latency = ov.compile_model(\n",
    "    ov_model, \n",
    "    \"CPU\", \n",
    "    {hints.performance_mode: hints.PerformanceMode.LATENCY}\n",
    ")\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_latency(x), val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9caf3b-059c-45b7-a036-fb29ef3fd1b8",
   "metadata": {},
   "source": [
    "## Async Inference\n",
    "\n",
    "–ü–µ—Ä–µ–ø–∏—à–µ–º  –±–µ–Ω—á–º–∞—Ä–∫ –ø–æ–¥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å. –û–Ω –¥–æ–ª–∂–µ–Ω –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ—á–µ—Ä–µ–¥—å –∏ –¥–∞—Ç–∞—Å–µ—Ç.\n",
    "\n",
    "### –ü—Ä–æ—Å—Ç–æ–π –ë–µ–Ω—á–º–∞—Ä–∫\n",
    "–ü—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–æ–ª–∂–Ω–∞ –∑–∞–º–µ—Ä–∏—Ç—å FPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7762d37-ee4f-4e4b-8df5-1974c934e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  1.98564s, FPS=439.152\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any, Optional\n",
    "\n",
    "\n",
    "def completion_callback(\n",
    "    infer_request: ov.InferRequest, user_data: Optional[Dict[str, Any]] = None\n",
    ") -> None:\n",
    "    ...\n",
    "\n",
    "infer_queue = ov.AsyncInferQueue(compiled_througput)\n",
    "infer_queue.set_callback(completion_callback)\n",
    "\n",
    "def simple_benchmark_async(queue, dataset):\n",
    "    tokenized_dataset = [{**tokenizer(sample[\"sentence\"], return_tensors=\"np\")} for sample in dataset]\n",
    "\n",
    "    # warmup\n",
    "    for data in tokenized_dataset[:10]:\n",
    "        queue.start_async(data)\n",
    "    queue.wait_all()\n",
    "\n",
    "    elapsed_start = perf_counter()\n",
    "    for idx, data in enumerate(tokenized_dataset):\n",
    "        queue.start_async(data) \n",
    "    queue.wait_all()\n",
    "    elapsed_end = perf_counter()\n",
    "    elapsed = elapsed_end - elapsed_start\n",
    "\n",
    "    return f\"{elapsed:.5f}s, FPS={(len(dataset) / elapsed):.3f}\"\n",
    "\n",
    "print(\"Openvino: \", simple_benchmark_async(infer_queue, val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f675e-f984-4ab1-94dc-6023e3b3cc58",
   "metadata": {},
   "source": [
    "### –î–æ–±–∞–≤–∏–º –ò–∑–º–µ—Ä–µ–Ω–∏–µ latency –í –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ë–µ–Ω—á–º–∞—Ä–∫\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º `completion_callback` –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0808d06-8d27-457f-af01-2e62bc8252ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  2.00049s, FPS=435.893, latency: 0.00000s, 0.00143s, 0.01041s\n"
     ]
    }
   ],
   "source": [
    "def completion_callback(\n",
    "    infer_request: ov.InferRequest,\n",
    "    user_data: Dict[str, Any],\n",
    ") -> None:\n",
    "    end = perf_counter()  # –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è, –∑–∞–º–µ–Ω—è–µ–º –≤—Ä–µ–º—è\n",
    "    idx = user_data[\"idx\"]\n",
    "    times = user_data[\"times\"]\n",
    "    times[idx] = end - times[idx]  # –≤—ã—á–∏—Ç–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ \n",
    "\n",
    "\n",
    "# –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –æ—á–µ—Ä–µ–¥—å, –ø–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–∏–º –∫–æ–ª–ª–±—ç–∫\n",
    "infer_queue.set_callback(completion_callback)\n",
    "\n",
    "\n",
    "def benchmark_async(queue, dataset):\n",
    "    tokenized_dataset = [{**tokenizer(sample[\"sentence\"], return_tensors=\"np\")} for sample in dataset]\n",
    "    times = [0 for _ in range(len(dataset))]\n",
    "\n",
    "    # warmup\n",
    "    for data in tokenized_dataset[:10]:\n",
    "        queue.start_async(data, {\"idx\": 0, \"times\": times})\n",
    "    queue.wait_all()\n",
    "    \n",
    "    start = perf_counter()\n",
    "    for idx, data in enumerate(tokenized_dataset):\n",
    "        # –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞ —Ä–µ–∫–≤–µ—Å—Ç–∞ –≤ –º–∞—Å—Å–∏–≤ –ø–æ –∏–Ω–¥–µ–∫—Å—É –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        times[idx] = perf_counter()\n",
    "        # –ø–µ—Ä–µ–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å –∏ –º–∞—Å—Å–∏–≤ —Å –Ω–∞—á–∞–ª–∞–º–∏ –≤–º–µ—Å—Ç–µ —Å –≤—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "        queue.start_async(data, {\"idx\": idx, \"times\": times})\n",
    "    # –∂–¥—ë–º –ø–æ–∫–∞ –∑–∞–≤–µ—Ä—à–∞—Ç—Å—è –≤—Å–µ —Ä–µ–∫–≤–µ—Å—Ç—ã\n",
    "    queue.wait_all()\n",
    "\n",
    "    # –∑–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –∫–æ–Ω—Ü–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n",
    "    end = perf_counter()\n",
    "    # –¥–ª—è –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è —É–∂–µ –Ω–µ–ª—å–∑—è –±—Ä–∞—Ç—å sum(times), —Ç–∞–∫ –∫–∞–∫ —Ä–µ–∫–≤–µ—Å—Ç—ã –∏—Å–ø–æ–ª–Ω—è—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ\n",
    "    elapsed = end - start\n",
    "    \n",
    "    return (\n",
    "        f\"{elapsed:.5f}s, FPS={(len(dataset) / elapsed):.3f}, \"\n",
    "        f\"latency: {min(times):.5f}s, {median(times):.5f}s, {max(times):.5f}s\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Openvino: \", benchmark_async(infer_queue, val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d6b8a",
   "metadata": {},
   "source": [
    "`InferRequest` –æ–±—ä–µ–∫—Ç —Å–∞–º –∑–∞–º–µ—Ä—è–µ—Ç latency –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, –ø–æ—ç—Ç–æ–º—É –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –¥–æ—Å—Ç–∞—Ç—å –≤—Ä–µ–º—è –æ—Ç—Ç—É–¥–∞. –í—Ä–µ–º—è –∑–∞–º–µ—Ä—è–µ—Ç—Å—è –≤ –ø–ª—é—Å–∞—Ö, –ø–æ—ç—Ç–æ–º—É latency –ø–æ–ª—É—á–∞–µ—Ç—Å—è –Ω–µ–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ. benchmark app –¥–ª—è –∑–∞–º–µ—Ä–æ–≤ latency —Ç–æ–∂–µ –±–µ—Ä—ë—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–∫–≤–µ—Å—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latency_from_ir_completion_callback(\n",
    "    infer_request: ov.InferRequest,\n",
    "    user_data: Dict[str, Any],\n",
    ") -> None:\n",
    "    times = user_data[\"times\"]\n",
    "    idx = user_data[\"idx\"]\n",
    "    times[idx] = infer_request.latency * 1e-3  # ms -> s\n",
    "\n",
    "\n",
    "infer_queue.set_callback(latency_from_ir_completion_callback)\n",
    "print(\"Openvino: \", benchmark_async(infer_queue, val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9485b",
   "metadata": {},
   "source": [
    "### Async Accuracy Evaluation\n",
    "\n",
    "–ù–∞–ø–∏—à–∏–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–º–µ—Ä—è–µ—Ç `accuracy` –≤ —Ä–µ–∂–∏–º–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º –∏–∑ `InferRequest` –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ `infer_request.get_tensor(\"<output_name>\").data`. –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞:\n",
    "```python\n",
    "def accuracy_evaluate(model, dataset=val_dataset, accuracy=accuracy):   \n",
    "    for sample in dataset:\n",
    "        tokenized = {**tokenizer(sample[\"sentence\"], return_tensors=\"pt\")}\n",
    "        logits = model(tokenized)[\"logits\"]\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        accuracy.add(references=sample[\"label\"], predictions=pred)\n",
    "\n",
    "    return accuracy.compute()[\"accuracy\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e9cd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:02<00:00, 434.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9013761467889908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "def completion_callback(\n",
    "    infer_request: ov.InferRequest,\n",
    "    user_data: Dict[str, Any],\n",
    ") -> None:\n",
    "    logits = infer_request.get_tensor(\"logits\").data\n",
    "    pred = np.argmax(logits, axis=1)\n",
    "\n",
    "    predictions.append(pred.item())\n",
    "    references.append(user_data[\"label\"])\n",
    "\n",
    "\n",
    "# –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –æ—á–µ—Ä–µ–¥—å, –ø–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–∏–º –∫–æ–ª–ª–±—ç–∫\n",
    "infer_queue.set_callback(completion_callback)\n",
    "\n",
    "\n",
    "def async_accuracy_evaluate(queue, dataset=val_dataset, accuracy=accuracy):\n",
    "\n",
    "    \n",
    "    for sample in tqdm(dataset):\n",
    "        tokenized = {**tokenizer(sample[\"sentence\"], return_tensors=\"np\")}\n",
    "        user_data = {\"label\": sample[\"label\"]}\n",
    "        queue.start_async(tokenized, user_data) \n",
    "\n",
    "\n",
    "    queue.wait_all()\n",
    "    accuracy.add_batch(references=references, predictions=predictions)\n",
    "    return accuracy.compute()[\"accuracy\"]\n",
    "\n",
    "\n",
    "print(f\"Model accuracy: {async_accuracy_evaluate(infer_queue)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d2dc7-572e-4c17-b7f0-e7efdff8f0bc",
   "metadata": {},
   "source": [
    "## Benchmark App\n",
    "\n",
    "### –ò–∑–º–µ—Ä–∏–º –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ú–æ–¥–µ–ª–∏ —Å –ü–æ–º–æ—â—å—é CLI benchmark_app\n",
    "\n",
    "–ß—Ç–æ–±—ã –Ω–µ –∂–¥–∞—Ç—å –ø–æ –º–∏–Ω—É—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–ª–∞–≥ `-t 30`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0092a0-5b06-42b5-aa3c-0571ad6d3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 43.67 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [?,?]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [?,2]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input_ids': [1,128], '63': [1,128], 'token_type_ids': [1,128]\n",
      "[ INFO ] Reshape model took 10.78 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [1,128]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [1,2]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 821.49 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model195\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   VALUE_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_GROUP_SIZE: 0\n",
      "[ INFO ]   VALUE_CACHE_GROUP_SIZE: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input_ids'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input '63'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input 'token_type_ids'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input_ids' with random values \n",
      "[ INFO ] Fill input '63' with random values \n",
      "[ INFO ] Fill input 'token_type_ids' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 30000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 78.89 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            3060 iterations\n",
      "[ INFO ] Duration:         30116.34 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        93.08 ms\n",
      "[ INFO ]    Average:       117.87 ms\n",
      "[ INFO ]    Min:           48.33 ms\n",
      "[ INFO ]    Max:           1508.28 ms\n",
      "[ INFO ] Throughput:   101.61 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m \"bert.xml\" -shape [1,128] -t 30 | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bb3fa-1814-4bfe-bb6b-23b508ee8c69",
   "metadata": {},
   "source": [
    "###  –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —á—Ç–æ–±—ã —É–≤–µ–ª–∏—á–∏—Ç—å FPS –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ\n",
    "\n",
    "101 FPS -> 156 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f04ae9-1461-4fa6-a512-8e5eb1e91214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 18.68 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [?,?]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [?,2]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input_ids': [1,128], '63': [1,128], 'token_type_ids': [1,128]\n",
      "[ INFO ] Reshape model took 0.99 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [1,128]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [1,2]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 229.64 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model195\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   VALUE_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_GROUP_SIZE: 0\n",
      "[ INFO ]   VALUE_CACHE_GROUP_SIZE: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input_ids'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input '63'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input 'token_type_ids'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input_ids' with random values \n",
      "[ INFO ] Fill input '63' with random values \n",
      "[ INFO ] Fill input 'token_type_ids' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 30000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 28.53 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            4716 iterations\n",
      "[ INFO ] Duration:         30121.92 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        74.37 ms\n",
      "[ INFO ]    Average:       76.45 ms\n",
      "[ INFO ]    Min:           55.72 ms\n",
      "[ INFO ]    Max:           215.39 ms\n",
      "[ INFO ] Throughput:   156.56 FPS\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p benchmark_report\n",
    "!benchmark_app -hint throughput -m model.xml -t 30 -shape [1,128] -t 30 -report_folder benchmark_report -pc -pcsort simple_sort \\\n",
    "-report_type average_counters | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 3 benchmark_report/benchmark_sorted_report.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61649fb9",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–º–µ—Ä –≤—Å–µ–≥–¥–∞ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º–∏ perf_counter'–∞–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å–±–æ—Ä —Ç–∞–∫–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–º–µ–¥–ª—è–µ—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99432787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"ov_config.json\", \"w\") as config_file:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"CPU\": {\n",
    "                \"NUM_STREAMS\": 24,\n",
    "                \"INFERENCE_NUM_THREADS\": 48,\n",
    "            }\n",
    "        },\n",
    "        config_file, \n",
    "    )\n",
    "\n",
    "!benchmark_app -m \"bert.xml\" -shape [1,128] -d CPU -load_config ov_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7505846",
   "metadata": {},
   "source": [
    "–ó–∞ —Å—á—ë—Ç —É—Ö—É–¥—à–µ–Ω–∏—è latency —É–¥–∞–ª–æ—Å—å –Ω–µ–º–Ω–æ–≥–æ –ø–æ–≤—ã—Å–∏—Ç—å throughput.\n",
    "\n",
    "> ‚ö†Ô∏è –¢–∞–∫–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è –Ω—É–∂–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ –∂–µ–ª–µ–∑–µ, –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3523e-1299-4881-a66d-ec2febd54a84",
   "metadata": {},
   "source": [
    "## NNCF\n",
    "\n",
    "### –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "–ö–≤–∞–Ω—Ç–∏–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. –ó–∞–º–µ—Ä–∏–º accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2aeb8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  11.09594s, FPS=78.587, latency: 0.00203s, 0.00402s, 0.01728s\n"
     ]
    }
   ],
   "source": [
    "ov_model = ov.convert_model(hf_model, example_input= dict(inputs))\n",
    "\n",
    "config = {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    "compiled_througput = ov.compile_model(ov_model, \"CPU\", config)\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_througput(x), val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe28bd-7637-4abc-905e-62bcbe2d4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nncf\n",
    "\n",
    "\n",
    "def transform_fn(text):\n",
    "    return {**tokenizer(text[\"sentence\"], return_tensors=\"np\")}\n",
    "\n",
    "\n",
    "# –≤–æ–∑—å–º—ë–º –¥–ª—è –∫–∞–ª–∏–±—Ä–∞—Ü–∏–∏ –¥—Ä—É–≥–æ–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "test_dataset = load_dataset(\"glue\", \"sst2\", split=\"test[:300]\")\n",
    "calibration_dataset = nncf.Dataset(test_dataset, transform_fn)\n",
    "quntized_model = nncf.quantize(\n",
    "    ov_model, \n",
    "    calibration_dataset=calibration_dataset,\n",
    "    preset=nncf.QuantizationPreset.MIXED,\n",
    "    target_device=nncf.TargetDevice.CPU,  # –≤–∞–∂–Ω–æ\n",
    "    model_type=nncf.ModelType.TRANSFORMER,  # –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ!\n",
    ")\n",
    "ov.save_model(quntized_model, \"qbert.xml\", compress_to_fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eb14279-03c3-45a9-8898-f8dd8246343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO accuracy: 0.8474770642201835\n"
     ]
    }
   ],
   "source": [
    "compiled_quantized = ov.compile_model(quntized_model)\n",
    "print(f\"OpenVINO accuracy: {accuracy_evaluate(compiled_quantized)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48201eff",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–∏–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31b5534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO accuracy: 0.9013761467889908\n"
     ]
    }
   ],
   "source": [
    "print(f\"OpenVINO accuracy: {accuracy_evaluate(compiled_througput)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390b0ad-89d2-4d1a-bf8e-eaec372ce89c",
   "metadata": {},
   "source": [
    "–ó–∞–º–µ—Ä–∏–º FPS –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é benchmark —Ñ—É–Ω–∫—Ü–∏–∏ –∏–ª–∏ benchmark_app:\n",
    "\n",
    "156 FPS -> 401 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e7741-ff55-49ec-9715-700727e01f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 18.73 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [?,?]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [?,2]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input_ids': [1,128], '63': [1,128], 'token_type_ids': [1,128]\n",
      "[ INFO ] Reshape model took 2.00 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [1,128]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [1,2]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 424.93 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model54\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   VALUE_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_GROUP_SIZE: 0\n",
      "[ INFO ]   VALUE_CACHE_GROUP_SIZE: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input_ids'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input '63'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input 'token_type_ids'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input_ids' with random values \n",
      "[ INFO ] Fill input '63' with random values \n",
      "[ INFO ] Fill input 'token_type_ids' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 30000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 13.28 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            12060 iterations\n",
      "[ INFO ] Duration:         30026.83 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        28.06 ms\n",
      "[ INFO ]    Average:       29.77 ms\n",
      "[ INFO ]    Min:           17.47 ms\n",
      "[ INFO ]    Max:           125.07 ms\n",
      "[ INFO ] Throughput:   401.64 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m \"qbert.xml\" -shape [1,128] -t 30 | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e956c-bf5b-43b6-94e5-120dd582609e",
   "metadata": {},
   "source": [
    "### Accuracy Control\n",
    "\n",
    "–ö–≤–∞–Ω—Ç–∏–∑—É–µ–º –º–æ–¥–µ–ª—å —Ç–∞–∫, —á—Ç–æ–±—ã –ø–æ—Ç–µ—Ä—è accuracy –±—ã–ª–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc946fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ä–∞–∑–¥–µ–ª–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "validation_dataset = list(val_dataset)\n",
    "final_test_dataset, validation_dataset = validation_dataset[:-300], validation_dataset[-300:]\n",
    "validation_dataset = nncf.Dataset(validation_dataset, transform_fn)\n",
    "\n",
    "quntized_model = nncf.quantize_with_accuracy_control(\n",
    "    model=ov_model,\n",
    "    calibration_dataset=calibration_dataset,\n",
    "    preset=nncf.QuantizationPreset.PERFORMANCE,\n",
    "    validation_dataset=validation_dataset,\n",
    "    validation_fn=accuracy_evaluate,  # —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–º–µ—Ä–∞ accuracy –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è\n",
    "    max_drop=0.01,\n",
    "    target_device=nncf.TargetDevice.CPU,\n",
    "    drop_type=nncf.DropType.ABSOLUTE,\n",
    "    # —É–±–µ—Ä—ë–º —Ç–∏–ø –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å accuracy drop –±–æ–ª—å—à–µ 1%\n",
    "    # –∏–Ω–∞—á–µ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –±—É–¥–µ—Ç —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –¥–µ—Ñ–æ–ª—Ç–Ω–æ–π ü§∑\n",
    "    # model_type=nncf.ModelType.TRANSFORMER, \n",
    ")\n",
    "ov.save_model(quntized_model, \"qbert_acc.xml\", compress_to_fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3aaeac-a8ea-4a3c-948a-4be72524c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_quantized_acc = ov.compile_model(\n",
    "    \"qbert_acc.xml\", \"CPU\", {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    ")\n",
    "\n",
    "print(f\"Openvino: {accuracy_evaluate(compiled_througput, final_test_dataset)}\")\n",
    "print(f\"Quantized Openvino :  {accuracy_evaluate(compiled_quantized, final_test_dataset)}\")\n",
    "print(f\"Openvino quantized with acc:  {accuracy_evaluate(compiled_quantized_acc, final_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15296d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino_tokenizers import convert_tokenizer, connect_models\n",
    "\n",
    "\n",
    "def get_connected_model(hf_model, tokenizer):\n",
    "    example_input = {**tokenizer(\"test\", return_tensors=\"pt\")}\n",
    "    ov_model = ov.convert_model(hf_model, example_input=example_input)\n",
    "    ov_tokenizer = convert_tokenizer(tokenizer)\n",
    "    return connect_models(ov_tokenizer, ov_model)\n",
    "\n",
    "\n",
    "get_connected_model(hf_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab371f7",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –≤–∏–¥–Ω–æ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ:\n",
    "- –û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π –¥—Ä–æ–ø –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–∏—á–µ–≥–æ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç.\n",
    "- –£–∫–∞–∑–∞—Ç—å —Ç–∏–ø –º–æ–¥–µ–ª–∏ –±—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–µ–µ, —á–µ–º –¥–∞—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "44fd4304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO accuracy: 0.8956422018348624\n"
     ]
    }
   ],
   "source": [
    "ov.save_model(quntized_model_best, \"qbert_best.xml\", compress_to_fp16 = False)\n",
    "\n",
    "compiled_quantized_best = ov.compile_model(quntized_model_best)\n",
    "print(f\"OpenVINO accuracy: {accuracy_evaluate(compiled_quantized_best)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3669da21",
   "metadata": {},
   "source": [
    "156 FPS -> 285.53 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23a6a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2025.0.0-17942-1f68be9f594-releases/2025/0\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 17.17 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [?,?]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [?,2]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input_ids': [1,128], '63': [1,128], 'token_type_ids': [1,128]\n",
      "[ INFO ] Reshape model took 4.44 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ]     attention_mask , 63 (node: attention_mask) : i64 / [...] / [1,128]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [1,2]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 408.40 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model54\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 12\n",
      "[ INFO ]   NUM_STREAMS: 12\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 16\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: False\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   MODEL_DISTRIBUTION_POLICY: set()\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 32\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   VALUE_CACHE_PRECISION: <Type: 'uint8_t'>\n",
      "[ INFO ]   KEY_CACHE_GROUP_SIZE: 0\n",
      "[ INFO ]   VALUE_CACHE_GROUP_SIZE: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input_ids'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input '63'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input 'token_type_ids'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input_ids' with random values \n",
      "[ INFO ] Fill input '63' with random values \n",
      "[ INFO ] Fill input 'token_type_ids' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 12 inference requests, limits: 30000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 18.05 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            8580 iterations\n",
      "[ INFO ] Duration:         30049.28 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        38.61 ms\n",
      "[ INFO ]    Average:       41.91 ms\n",
      "[ INFO ]    Min:           23.98 ms\n",
      "[ INFO ]    Max:           205.59 ms\n",
      "[ INFO ] Throughput:   285.53 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -hint throughput -m qbert_best.xml -t 30 -shape \"input_ids[1,128],attention_mask[1,128],token_type_ids[1,128]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ae888f-f342-419b-8bb4-a9f226920821",
   "metadata": {},
   "source": [
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ\n",
    "\n",
    "–î–æ–±–∞–≤–∏–º –≤ –º–æ–¥–µ–ª—å:\n",
    "1. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Å –ø–æ–º–æ—â—å—é `openvino-tokenizers`\n",
    "2. –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –≤ –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –æ–Ω–∞ —Å—Ä–∞–∑—É –æ—Ç–¥–∞–≤–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç `np.argmax(logits, axis=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca177580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --pre -U openvino-tokenizers --extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly git+https://github.com/openvinotoolkit/nncf.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bb51d-32da-4526-a60c-d06a1f59b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino_tokenizers import convert_tokenizer, connect_models\n",
    "\n",
    "\n",
    "def get_connected_model(hf_model, tokenizer):\n",
    "    example_input = {**tokenizer(\"test\", return_tensors=\"pt\")}\n",
    "    ov_model = ov.convert_model(hf_model, example_input=example_input)\n",
    "    ov_tokenizer = convert_tokenizer(tokenizer)\n",
    "    return connect_models(ov_tokenizer, ov_model)\n",
    "\n",
    "\n",
    "get_connected_model(hf_model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
